{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbFmQdsZs5eW"
   },
   "outputs": [],
   "source": [
    "# ATTENTION: Please do not alter any of the provided code in the exercise. Only add your own code where indicated\n",
    "# ATTENTION: Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position.\n",
    "# ATTENTION: Please use the provided epoch values when training.\n",
    "\n",
    "# Import all the necessary files!\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xJZ5glPPCRz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 74, 74, 32)   864         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 74, 74, 32)   96          conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 74, 74, 32)   0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 72, 72, 32)   9216        activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 72, 72, 32)   96          conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 72, 72, 32)   0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 72, 72, 64)   18432       activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 72, 72, 64)   192         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 72, 72, 64)   0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 35, 35, 80)   240         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 35, 35, 80)   0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 33, 33, 192)  138240      activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 33, 33, 192)  576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 33, 33, 192)  0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 16, 16, 64)   192         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 16, 16, 64)   0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 16, 16, 96)   55296       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 16, 16, 48)   144         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 16, 16, 96)   288         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 16, 16, 48)   0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 16, 16, 96)   0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 16, 16, 64)   76800       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 16, 16, 96)   82944       activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 16, 16, 64)   192         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 16, 16, 64)   192         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 16, 16, 96)   288         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 16, 16, 32)   96          conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 16, 16, 64)   0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 16, 16, 64)   0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 16, 16, 96)   0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 16, 16, 32)   0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_193[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 16, 16, 64)   192         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 16, 16, 64)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 16, 16, 96)   55296       activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 16, 16, 48)   144         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 16, 16, 96)   288         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 16, 16, 48)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 16, 16, 96)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 16, 16, 64)   76800       activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 16, 16, 96)   82944       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 16, 16, 64)   192         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 16, 16, 64)   192         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 16, 16, 96)   288         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 16, 16, 64)   192         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 16, 16, 64)   0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 16, 16, 64)   0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 16, 16, 96)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 16, 16, 64)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_200[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "                                                                 activation_205[0][0]             \n",
      "                                                                 activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 16, 16, 64)   192         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 16, 16, 64)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 16, 16, 96)   55296       activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 16, 16, 48)   144         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 16, 16, 96)   288         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 16, 16, 48)   0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 16, 16, 96)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 16, 16, 64)   76800       activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 16, 16, 96)   82944       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 16, 16, 64)   192         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 16, 16, 64)   192         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 16, 16, 96)   288         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 16, 16, 64)   192         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 16, 16, 64)   0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 16, 16, 64)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 16, 16, 96)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 16, 16, 64)   0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_207[0][0]             \n",
      "                                                                 activation_209[0][0]             \n",
      "                                                                 activation_212[0][0]             \n",
      "                                                                 activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 16, 16, 64)   192         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 16, 16, 64)   0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 16, 16, 96)   55296       activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 16, 16, 96)   288         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 16, 16, 96)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 7, 7, 96)     82944       activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 7, 7, 384)    1152        conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 7, 7, 96)     288         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 7, 7, 384)    0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 7, 7, 96)     0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_214[0][0]             \n",
      "                                                                 activation_217[0][0]             \n",
      "                                                                 max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 7, 7, 128)    384         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 7, 7, 128)    0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 7, 7, 128)    114688      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 7, 7, 128)    384         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 7, 7, 128)    0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 7, 7, 128)    114688      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 7, 7, 128)    384         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 7, 7, 128)    384         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 7, 7, 128)    0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 7, 7, 128)    0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 7, 7, 128)    114688      activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 7, 7, 128)    114688      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 7, 7, 128)    384         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 7, 7, 128)    384         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 7, 7, 128)    0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 7, 7, 128)    0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 7, 7, 192)    172032      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 7, 7, 192)    172032      activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 7, 7, 192)    576         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 7, 7, 192)    576         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 7, 7, 192)    576         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 7, 7, 192)    576         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 7, 7, 192)    0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 7, 7, 192)    0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 7, 7, 192)    0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 7, 7, 192)    0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_218[0][0]             \n",
      "                                                                 activation_221[0][0]             \n",
      "                                                                 activation_226[0][0]             \n",
      "                                                                 activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 7, 7, 160)    480         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 7, 7, 160)    0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 7, 7, 160)    179200      activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 7, 7, 160)    480         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 7, 7, 160)    0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 7, 7, 160)    179200      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 7, 7, 160)    480         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 7, 7, 160)    480         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 7, 7, 160)    0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 7, 7, 160)    0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 7, 7, 160)    179200      activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 7, 7, 160)    179200      activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 7, 7, 160)    480         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 7, 7, 160)    480         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 7, 7, 160)    0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 7, 7, 160)    0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 7, 7, 192)    215040      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 7, 7, 192)    215040      activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 7, 7, 192)    576         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 7, 7, 192)    576         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 7, 7, 192)    576         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 7, 7, 192)    576         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 7, 7, 192)    0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 7, 7, 192)    0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 7, 7, 192)    0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 7, 7, 192)    0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_228[0][0]             \n",
      "                                                                 activation_231[0][0]             \n",
      "                                                                 activation_236[0][0]             \n",
      "                                                                 activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 7, 7, 160)    480         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 7, 7, 160)    0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 7, 7, 160)    179200      activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 7, 7, 160)    480         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 7, 7, 160)    0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 7, 7, 160)    179200      activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 7, 7, 160)    480         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 7, 7, 160)    480         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 7, 7, 160)    0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 7, 7, 160)    0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 7, 7, 160)    179200      activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 7, 7, 160)    179200      activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 7, 7, 160)    480         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 7, 7, 160)    480         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 7, 7, 160)    0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 7, 7, 160)    0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 7, 7, 192)    215040      activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 7, 7, 192)    215040      activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 7, 7, 192)    576         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 7, 7, 192)    576         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 7, 7, 192)    576         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 7, 7, 192)    576         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 7, 7, 192)    0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 7, 7, 192)    0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 7, 7, 192)    0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 7, 7, 192)    0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_238[0][0]             \n",
      "                                                                 activation_241[0][0]             \n",
      "                                                                 activation_246[0][0]             \n",
      "                                                                 activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 7, 7, 192)    576         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 7, 7, 192)    0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 7, 7, 192)    258048      activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 7, 7, 192)    576         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 7, 7, 192)    0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 7, 7, 192)    258048      activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 7, 7, 192)    576         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 7, 7, 192)    576         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 7, 7, 192)    0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 7, 7, 192)    0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 7, 7, 192)    258048      activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 7, 7, 192)    258048      activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 7, 7, 192)    576         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 7, 7, 192)    576         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 7, 7, 192)    0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 7, 7, 192)    0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 7, 7, 192)    258048      activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 7, 7, 192)    258048      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 7, 7, 192)    576         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 7, 7, 192)    576         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 7, 7, 192)    576         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 7, 7, 192)    576         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 7, 7, 192)    0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 7, 7, 192)    0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 7, 7, 192)    0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 7, 7, 192)    0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
      "                                                                 activation_251[0][0]             \n",
      "                                                                 activation_256[0][0]             \n",
      "                                                                 activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 7, 7, 192)    576         conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 7, 7, 192)    0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 7, 7, 192)    258048      activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 7, 7, 192)    576         conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 7, 7, 192)    0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 7, 7, 192)    258048      activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 7, 7, 192)    576         conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 7, 7, 192)    576         conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 7, 7, 192)    0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 7, 7, 192)    0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 3, 3, 320)    552960      activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 3, 3, 192)    331776      activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 3, 3, 320)    960         conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 3, 3, 192)    576         conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 3, 3, 320)    0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 3, 3, 192)    0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_259[0][0]             \n",
      "                                                                 activation_263[0][0]             \n",
      "                                                                 max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 3, 3, 448)    1344        conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 3, 3, 448)    0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 3, 3, 384)    1548288     activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 3, 3, 384)    1152        conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 3, 3, 384)    1152        conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 3, 3, 384)    0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 3, 3, 384)    0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 3, 3, 384)    442368      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 3, 3, 384)    442368      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 3, 3, 384)    442368      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 3, 3, 384)    442368      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_25 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 3, 3, 384)    1152        conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 3, 3, 384)    1152        conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 3, 3, 384)    1152        conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 3, 3, 384)    1152        conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 3, 3, 320)    960         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 3, 3, 384)    0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 3, 3, 384)    0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 3, 3, 384)    0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 3, 3, 384)    0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 3, 3, 192)    576         conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 3, 3, 320)    0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_266[0][0]             \n",
      "                                                                 activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 3, 3, 768)    0           activation_270[0][0]             \n",
      "                                                                 activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 3, 3, 192)    0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_264[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 3, 3, 448)    1344        conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 3, 3, 448)    0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 3, 3, 384)    1548288     activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 3, 3, 384)    1152        conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 3, 3, 384)    1152        conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 3, 3, 384)    0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 3, 3, 384)    0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 3, 3, 384)    442368      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 3, 3, 384)    442368      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 3, 3, 384)    442368      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 3, 3, 384)    442368      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_26 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 3, 3, 384)    1152        conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 3, 3, 384)    1152        conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 3, 3, 384)    1152        conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 3, 3, 384)    1152        conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 3, 3, 320)    960         conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 3, 3, 384)    0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 3, 3, 384)    0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 3, 3, 384)    0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 3, 3, 384)    0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
      "                                                                 activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
      "                                                                 activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 activation_281[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "path_inception = f\"{getcwd()}/../tmp2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "# Import the inception model  \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# Create an instance of the inception model from the local pre-trained weights\n",
    "local_weights_file = path_inception\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape = (150,150,3),  # Your Code Here\n",
    "                               include_top=False,\n",
    "                               weights= None)\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Make all the layers in the pre-trained model non-trainable\n",
    "for layer in pre_trained_model.layers:\n",
    "  # Your Code Here\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Print the model summary\n",
    "pre_trained_model.summary()\n",
    "\n",
    "# Expected Output is extremely large, but should end with:\n",
    "\n",
    "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
    "#                                                                 activation_276[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
    "#                                                                 activation_280[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
    "#                                                                 mixed9_1[0][0]                   \n",
    "#                                                                 concatenate_5[0][0]              \n",
    "#                                                                 activation_281[0][0]             \n",
    "#==================================================================================================\n",
    "#Total params: 21,802,784\n",
    "#Trainable params: 0\n",
    "#Non-trainable params: 21,802,784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFsUlwdfs_wg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7')# Your Code Here\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output  # Your Code Here\n",
    "\n",
    "# Expected Output:\n",
    "# ('last layer output shape: ', (None, 7, 7, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bsWZWp5oMq9"
   },
   "outputs": [],
   "source": [
    "# Define a Callback class that stops training once accuracy reaches 97.0%\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('acc')>0.97):\n",
    "      print(\"\\nReached 97.0% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation=\"relu\")(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation=\"sigmoid\")(x)           \n",
    "\n",
    "model = Model(pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = \"binary_crossentropy\", \n",
    "              metrics = [\"acc\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Expected output will be large. Last few lines should be:\n",
    "\n",
    "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
    "#                                                                  activation_251[0][0]             \n",
    "#                                                                  activation_256[0][0]             \n",
    "#                                                                  activation_257[0][0]             \n",
    "# __________________________________________________________________________________________________\n",
    "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
    "# __________________________________________________________________________________________________\n",
    "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
    "# ==================================================================================================\n",
    "# Total params: 47,512,481\n",
    "# Trainable params: 38,537,217\n",
    "# Non-trainable params: 8,975,264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HrnL_IQ8knWA"
   },
   "outputs": [],
   "source": [
    "# Get the Horse or Human dataset\n",
    "path_horse_or_human = f\"{getcwd()}/../tmp2/horse-or-human.zip\"\n",
    "# Get the Horse or Human Validation dataset\n",
    "path_validation_horse_or_human = f\"{getcwd()}/../tmp2/validation-horse-or-human.zip\"\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree('/tmp')\n",
    "local_zip = path_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/training')\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip = path_validation_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/validation')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9okX7_ovskI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "527\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# Define our example directories and files\n",
    "train_dir = '/tmp/training'\n",
    "validation_dir = '/tmp/validation'\n",
    "\n",
    "train_horses_dir = os.path.join(train_dir, 'horses')  # Your Code Here\n",
    "train_humans_dir = os.path.join(train_dir, 'humans')  # Your Code Here\n",
    "validation_horses_dir = os.path.join(validation_dir, 'horses')  # Your Code Here\n",
    "validation_humans_dir = os.path.join(validation_dir, 'humans')  # Your Code Here\n",
    "\n",
    "train_horses_fnames = os.listdir(train_horses_dir)  # Your Code Here\n",
    "train_humans_fnames = os.listdir(train_humans_dir)  # Your Code Here\n",
    "validation_horses_fnames = os.listdir(validation_horses_dir)  # Your Code Here\n",
    "validation_humans_fnames = os.listdir(validation_humans_dir)  # Your Code Here\n",
    "\n",
    "print(len(train_horses_fnames))\n",
    "print(len(train_humans_fnames ))\n",
    "print(len(validation_horses_fnames))\n",
    "print(len(validation_humans_fnames))\n",
    "\n",
    "# Expected Output:\n",
    "# 500\n",
    "# 527\n",
    "# 128\n",
    "# 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4s8HckqGlnb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1/255,\n",
    "                                  rotation_range = 45,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip= True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1/255 )\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                   batch_size=20,\n",
    "                                                   class_mode='binary',\n",
    "                                                   target_size=(150,150))     \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                        batch_size=20,\n",
    "                                                        class_mode='binary',\n",
    "                                                        target_size=(150,150))\n",
    "\n",
    "# Expected Output:\n",
    "# Found 1027 images belonging to 2 classes.\n",
    "# Found 256 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Blhq2MAUeyGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "100/100 - 84s - loss: 0.2214 - acc: 0.9043 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 2/3\n",
      "100/100 - 83s - loss: 0.0724 - acc: 0.9696 - val_loss: 0.0071 - val_acc: 0.9960\n",
      "Epoch 3/3\n",
      "\n",
      "Reached 97.0% accuracy so cancelling training!\n",
      "100/100 - 82s - loss: 0.0459 - acc: 0.9809 - val_loss: 0.0717 - val_acc: 0.9798\n"
     ]
    }
   ],
   "source": [
    "# Run this and see how many epochs it should take before the callback\n",
    "# fires, and stops training at 97% accuracy\n",
    "\n",
    "callbacks = myCallback()\n",
    "history = model.fit_generator(train_generator,\n",
    "                             validation_data=validation_generator,\n",
    "                             steps_per_epoch=100,\n",
    "                             epochs = 3,\n",
    "                             validation_steps=50,\n",
    "                             verbose=2,\n",
    "                             callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2Fp6Se9rKuL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXhTVfrA8e9L2YWyKwqyyVqgxVK2YUdBVARZFBBEVEQdUYdRZ3T0pw6OOg7q4K6oMDAqyLjjiAwgCChbQcoqFAGlUKFsZRcK5/fHuWmT0CVt094kfT/Pk4fknnuTN7fhzcnZrhhjUEopFblKuR2AUkqpoqWJXimlIpwmeqWUinCa6JVSKsJpoldKqQiniV4ppSKcJvoSSESiROSYiNQL5r5uEpHGIhL0scIicqWI7PR6vEVEugaybwFe6x0R+UtBj1cqJ6XdDkDlTUSOeT2sCPwGnHUe32mMeT8/z2eMOQtUCva+JYExplkwnkdExgAjjTE9vJ57TDCeWyl/mujDgDEmM9E6NcYxxpj5Oe0vIqWNMRnFEZtSedHPo/u06SYCiMjfRORDEZkhIkeBkSLSSUSWi8hhEUkVkZdFpIyzf2kRMSLSwHn8nlM+R0SOisgyEWmY332d8qtFZKuIpIvIKyLynYiMziHuQGK8U0S2icghEXnZ69goEfmniBwQke1A31zOz6MiMtNv22si8qJzf4yIbHbez09ObTun50oRkR7O/Yoi8m8nto1AW799HxOR7c7zbhSR/s721sCrQFenWWy/17l90uv4u5z3fkBEPhORiwM5N/k5z554RGS+iBwUkV9F5E9er/N/zjk5IiKJInJJds1kIrLU83d2zudi53UOAo+JSBMRWei8xn7nvFXxOr6+8x7TnPKXRKS8E3MLr/0uFpETIlIjp/ersmGM0VsY3YCdwJV+2/4GnAauw355VwDaAR2wv9oaAVuBcc7+pQEDNHAevwfsBxKAMsCHwHsF2PdC4CgwwCn7I3AGGJ3Dewkkxs+BKkAD4KDnvQPjgI1AXaAGsNh+nLN9nUbAMeACr+feByQ4j69z9hGgF3ASiHXKrgR2ej1XCtDDuf88sAioBtQHNvnteyNwsfM3ucmJ4SKnbAywyC/O94Annft9nBjbAOWB14FvAjk3+TzPVYC9wP1AOSAaaO+UPQIkAU2c99AGqA409j/XwFLP39l5bxnA3UAU9vPYFLgCKOt8Tr4Dnvd6Pxuc83mBs39np2wy8LTX6zwAfOr2/8Nwu7kegN7y+QfLOdF/k8dxDwL/ce5nl7zf9Nq3P7ChAPveBizxKhMglRwSfYAxdvQq/wR40Lm/GNuE5Sm7xj/5+D33cuAm5/7VwJZc9v0SuMe5n1ui/8X7bwH83nvfbJ53A3Ctcz+vRD8NeMarLBrbL1M3r3OTz/N8M7Aqh/1+8sTrtz2QRL89jxiGeF4X6Ar8CkRls19nYAcgzuO1wKBg/7+K9Js23USOXd4PRKS5iPzX+Sl+BJgA1Mzl+F+97p8g9w7YnPa9xDsOY/9npuT0JAHGGNBrAT/nEi/AB8Bw5/5NzmNPHP1EZIXTrHAYW5vO7Vx5XJxbDCIyWkSSnOaHw0DzAJ8X7PvLfD5jzBHgEFDHa5+A/mZ5nOdLsQk9O7mV5cX/81hbRGaJyG4nhn/5xbDT2I5/H8aY77C/DrqISCugHvDfAsZUYmmijxz+QwvfwtYgGxtjooHHsTXsopSKrXECICKCb2LyV5gYU7EJwiOv4Z+zgCtFpA62aekDJ8YKwEfAs9hmlarA/wKM49ecYhCRRsAb2OaLGs7z/uj1vHkNBd2DbQ7yPF9lbBPR7gDi8pfbed4FXJbDcTmVHXdiqui1rbbfPv7v7znsaLHWTgyj/WKoLyJROcQxHRiJ/fUxyxjzWw77qRxooo9clYF04LjTmXVnMbzml0C8iFwnIqWx7b61iijGWcAfRKSO0zH359x2Nsb8im1e+Be22SbZKSqHbTdOA86KSD9sW3KgMfxFRKqKnWcwzqusEjbZpWG/8+7A1ug99gJ1vTtF/cwAbheRWBEph/0iWmKMyfEXUi5yO89fAPVEZJyIlBORaBFp75S9A/xNRC4Tq42IVMd+wf2K7fSPEpGxeH0p5RLDcSBdRC7FNh95LAMOAM+I7eCuICKdvcr/jW3quQmb9FU+aaKPXA8At2A7R9/CdpoWKWPMXmAo8CL2P+5lwA/YmlywY3wDWACsB1Zha+V5+QDb5p7ZbGOMOQyMBz7FdmgOwX5hBeIJ7C+LncAcvJKQMWYd8Aqw0tmnGbDC69h5QDKwV0S8m2A8x3+NbWL51Dm+HjAiwLj85XiejTHpQG9gMPbLZyvQ3SmeCHyGPc9HsB2j5Z0muTuAv2A75hv7vbfsPAG0x37hfAF87BVDBtAPaIGt3f+C/Tt4yndi/86/GWO+z+d7V2R1cCgVdM5P8T3AEGPMErfjUeFLRKZjO3ifdDuWcKQTplRQiUhf7AiXk9jheWewtVqlCsTp7xgAtHY7lnClTTcq2LoA27Ft01cBA7XzTBWUiDyLHcv/jDHmF7fjCVfadKOUUhFOa/RKKRXhQq6NvmbNmqZBgwZuh6GUUmFl9erV+40x2Q5nDrlE36BBAxITE90OQymlwoqI5Dg7XJtulFIqwmmiV0qpCKeJXimlIpwmeqWUinCa6JVSKsLlmehFZIqI7BORDTmUi3PJsG0isk5E4r3KbhGRZOd2SzADV0opFZhAavT/IpfrcWKv1tPEuY3FriqIs5zpE9hLmLUHnhCRaoUJVimlVP7lOY7eGLNYnAtD52AAMN1ZunS5szb3xUAPYJ4x5iCAiMzDfmHMKGzQ2Tl1Cp56CqKjc75VqWL/LVu2KCJQSqnQFIwJU3XwvWxYirMtp+3ncS5cMBagXr28LhSUvcOH4bnn4Ox5FyM7X7lyuX8h5PVF4bmVLw9S1NdsUkqpQgqJmbHGmMnYixqQkJBQoFXWateGM2fg5Ek4csTe0tOz7ud127XL97gzZ/J+zdKlg/OFccEF+oWhlCo6wUj0u/G9bmZdZ9tubPON9/ZFQXi9HIlAxYr2Vtv/Cpb59NtvBfvC2LsXkpOzHp88GVjchf2yiI6GSpUgKqerbiqlSqxgJPovgHEiMhPb8ZpujEkVkbnYa0B6OmD7YC9EERbKlYNateytMM6cgaNH8/dlceQIHDoEP/+c9fjYscBer1Klwn1ZREdD5cpQJqcrmSqlwk6eiV5EZmBr5jVFJAU7kqYMgDHmTeAr4BpgG3ACuNUpOygiT2Gv5wkwwdMxW5KUKQPVq9tbYZw9a78w8vNl4bmlpvo+DuQSBBUqFO7LwnMrV65w71spVXghd+GRhIQEo6tXFp1z5+D48YJ9YXjf0tMD6/guW7bwXxbR0faLR/sxlMqZiKw2xiRkVxYSnbGq+JQqZZtmKleGOtmOgQqMMb4d3/m57d4NmzdnfWGcPp3360VFFf7LwtPxXUrng6sSRhO9KpCi6vjOzy0tDX76Kav/I9CO78qVC/5l0bCh/bJQKpxooleuC3bHd0GaoX75JbCO76goiI2Fjh2hUyf7b+PG2qykQpsmehUxgtnxfezY+V8Ihw/Dhg2wfDm89x688Ybdv0YN6NAhK/G3b29r/0qFCk30SvmJirLNOFWqnF82dKj99+xZ28+wfHnWbc4c23chAjExWYm/Y0do0UL7BpR7dNSNUkGSng4rV/om/4POgOLoaFvT9yT/Dh3sLwGlgiW3UTea6JUqIsbYWdKepL9sGaxbZ4e4AjRp4lvrb93aLquhVEFoolcqRBw7BqtXZyX+Zctg3z5bVrEitGuXlfg7diz8iCZVcug4eqVCRKVK0L27vYGt9f/8c1biX74cXnwxa1G9Bg18E//ll+sy2yr/tEavVIg5dQp++ME3+e9yFvwuVw7i47MSf6dOULeuDu9U2nSjVNjbvRtWrMhK/ImJ9gsB4JJLfBN/27Z2yQhVsmiiVyrCnDljO3Y9iX/5cjtLGGyHblyc76SuRo201h/pNNErVQLs22dr/Z7Ev3Jl1izfmjV9E3+7dnYpCBU5tDNWqRLgwgvhuuvsDeykro0bfcf1f/mlLROBVq18k3+zZjqpK1JpjV6pEuTQofMndR0+bMuqVPFdyqFDB6hWLffnU6FDm26UUtk6dw62bvWd1LVhQ9akrmbNfCd1tWypk7pClSZ6pVTAjh61o3q8h3empdmyCy6wSzl4j+2/8EJ341WWttErpQJWuTL07GlvYCd17djhW+ufOBEyMmx5o0a+iT8uTid1hRqt0Sul8u3kSVizxncphz17bFn58nYsv/fY/sJczUwFRptulFJFLiXFt7ln9Wp79TCws3e9a/1t29ovBBU8muiVUsXu9GlISvKd1LVjhy0rUwbatPGt9TdooJO6CkMTvVIqJOzd6zu0c+VKOHHCll14oW/iT0iwi8CpwGiiV0qFpIyMrMszem5bttiyUqXsGv3ek7qaNNFJXTnRRK+UChsHDvhO6lqxwl69C+wErg4dspJ/+/ZQtaq78YYKTfRKqbB17hz8+KPv8M6NG+2wT7DX4/Wu9cfE2Ov+ljSa6JVSEeXIEVi1yneUz4EDtqxSpfOvz1urlrvxFgdN9EqpiGaMXabZO/EnJdmF3QAaN/Yd3hkba0f+RBJN9EqpEufECTuW35P4ly2DX3+1ZRUq2FE93sn/kkvcjbewNNErpUo8Y+wlGb1r/WvW2PH+APXq+Sb++Hh76cZwoWvdKKVKPBGbzOvVgxtvtNt++w3WrvWd1DVrli0rW9ZejN17bH+9euE5qUtr9Eop5SU11Xdc/6pVdm0fgNq1fWv9CQl2Rc9QoE03SilVQGfOwPr1vsk/OdmWRUXZjl3vWn/jxu7U+gud6EWkL/ASEAW8Y4z5u195fWAKUAs4CIw0xqQ4Zf8ArgVKAfOA+00uL6qJXikV6vbv970+74oVdh1/gOrVfRN/u3b26l15MsY+SXR0gWIqVBu9iEQBrwG9gRRglYh8YYzZ5LXb88B0Y8w0EekFPAvcLCK/AzoDsc5+S4HuwKICvROllAoBNWvCtdfaG9hhnJs3+07q+uorWyZiJ3FlTuqKPUGLUlsolbzFrvfgfYuPh8WLgx5vIJ2x7YFtxpjtNmiZCQwAvBN9DPBH5/5C4DPnvgHKA2UBAcoAewsftlJKhY6oKHux9VatYMwY4Nw5Dm9IYdV/97F8aQbLNlTmk2mX8u670UBFomlEe/bTiVJ0vLAcHVo2osbtXez6zUUgkERfB9jl9TgF6OC3TxIwCNu8MxCoLCI1jDHLRGQhkIpN9K8aYzYXPmyllAoBR4+eXyv/8UdITqbqyZP0xjaFEB2NadOM5Eu6s7x0F5YdbcXyX7rwdPKVnNsnsA+apMA1ApNGBT/MYA2vfBB4VURGA4uB3cBZEWkMtADqOvvNE5Guxpgl3geLyFhgLEC9evWCFJJSSgXB2bPw88/nJ/MtW+wQHY9SpaBhQ3tF9SuusP96brVrIyI0BZoCnlx+7Jid1OVp7jlypGjeQiCJfjdwqdfjus62TMaYPdgaPSJSCRhsjDksIncAy40xx5yyOUAnYInf8ZOByWA7Ywv2VpRSqhAOH84+mW/blnWpLLBLaDZrBn36+Cbzxo3zPcOqUiXo3t3eilIgiX4V0EREGmIT/DDgJu8dRKQmcNAYcw54BDsCB+AX4A4ReRbbdNMdmBSk2JVSKn8yMuxlrvyT+ZYtsG9f1n5RUXDZZTaBX321/bd5c/tvzZphN2sqz0RvjMkQkXHAXOzwyinGmI0iMgFINMZ8AfQAnhURg226ucc5/COgF7Ae2zH7tTFmdvDfhlJKeTlwIPtk/tNPdmC8R82aNnn365dVM2/eHBo1iqhVz3TClFIqPJ0+Ddu3n5/Mt2zJWrMYbMJu3Ni3mcVTO69e3b34g0zXulFKhSdjIC0t+9r59u1Z6xADXHSRTd6DBmUl8mbN7FXHS5fsVFey371SKjT89pvt9PSvmW/ZYjtJPcqVsxeOjY2FG27ISuhNm+o1BXOhiV4pVTyMsQvCZ5fMd+601wz0uOQSm8CHD/dtcqlXr2ReJ7CQNNErpYLr5Em76ld2Cd2zIAzYq380bWoXgxk5MiuZN20KlSu7F38E0kSvlMo/Y2D37uyT+S+/ZF25G+DSS20Tyy23+NbO69a1k4xUkdNEr5TK2bFjsHXr+cl861Y4fjxrv0qVbPLu3Bluuy0rmTdpEjoLtpdgmuiVKunOnbO1cP9kvmULpKRk7SdiR7A0awbduvnWzi+5JOwmEZUkmuiVKimOHMk+mW/dCqdOZe1XpYpN3j17nj/Fv0IF9+JXBaaJXqlIcvasHcGSXUL3X4CrUSObwK+80jehX3SR1s4jjCZ6pcLRoUPZJ/PkZDtj1KN6dZu8r7rKN5lfdlm+F+BS4UsTvVKh6swZ3wW4vGeHpqVl7Ve6dNYCXNdc4zvNv2ZN9+JXIUMTvVJu278/+2T+0092tUWPWrVsAu/f33e9loYNI2oBLhV8muiVKg6nT9vEnd165wcPZu1Xtqzt9IyJgYEDfRN6tWruxa/CmiZ6pYLFGLumeXbJfMcO3wW4ate2yXvIEN8FuOrXL/ELcKng00+UUvl16pRdgCu7hJ6enrVf+fJ2wlCbNjBsmO8U/ypV3ItflTia6JUKxIkTMH48zJtnhy96T/GvU8cm8BEjzl+AS6f4qxCgiV6pvOzfD9ddBytWwODBMGqUb+28UiW3I1QqV5rolcrN9u3Qty/s2gUffWQvaqFUmNFEr1ROVq+249IzMmD+fLtgl1JhSBsQlcrOnDnQvbtd2+W77zTJq7CmiV4pf1Om2Db5pk1h2TI7/FGpMKaJXikPY2DCBLj9drjiCvj2W7j4YrejUqrQtI1eKbDt8L//Pbz9tr0S0ttv67ICKmJojV6p48fh+uttcn/sMZg6VZO8iihao1cl2759cO21sGYNvPkm3Hmn2xEpFXSa6FXJlZxsx8inpsJnn9kOWKUikCZ6VTKtWAH9+tn7CxdChw7uxqNUEdI2elXyzJ5tr4caHQ3ff69JXkU8TfSqZHnrLdvx2rKlTfJNmrgdkVJFThO9KhmMsSNq7rrLtssvWmQvgq1UCaBt9CrynTkDd9wB06bBmDHwxht6cQ9VomiNXkW2o0dtp+u0afDXv8LkyZrkVYmjn3gVuVJT7Rj5devg3XfhttvcjkgpVwRUoxeRviKyRUS2icjD2ZTXF5EFIrJORBaJSF2vsnoi8j8R2Swim0SkQfDCVyoHP/4InTrB1q12lI0meVWC5ZnoRSQKeA24GogBhotIjN9uzwPTjTGxwATgWa+y6cBEY0wLoD2wLxiBK5Ujz7LCJ0/aTterr3Y7IqVcFUiNvj2wzRiz3RhzGpgJDPDbJwb4xrm/0FPufCGUNsbMAzDGHDPGnAhK5Epl59NP4coroUYNu8RwQoLbESnlukASfR1gl9fjFGebtyTAc421gUBlEakBNAUOi8gnIvKDiEx0fiH4EJGxIpIoIolpaWn5fxdKAbz6qr2ma5s2dox8o0ZuR6RUSAjWqJsHge4i8gPQHdgNnMV29nZ1ytsBjYDR/gcbYyYbYxKMMQm1atUKUkiqxDh3Dv78Z7j3XujfHxYsgJo13Y5KqZARSKLfDVzq9biusy2TMWaPMWaQMeZy4FFn22Fs7X+t0+yTAXwGxAclcqUATp+Gm2+Gf/wD7r4bPv4YKlZ0OyqlQkogiX4V0EREGopIWWAY8IX3DiJSU0Q8z/UIMMXr2Koi4qmm9wI2FT5spYD0dNvR+sEH8Mwz8NprEHVey6BSJV6eid6piY8D5gKbgVnGmI0iMkFE+ju79QC2iMhW4CLgaefYs9hmmwUish4Q4O2gvwtV8uzeDd26weLFMH06PPIIiLgdlVIhSYwxbsfgIyEhwSQmJrodhgplGzfa9WrS021TTe/ebkeklOtEZLUxJtthZroEggov334LXbrA2bO2Nq9JXqk8aaJX4WPWLOjTB2rXtmPk27RxOyKlwoImehUe/vlPGDoU2re3M1/r13c7IqXChiZ6FdrOnYPx4+GPf7SToebNg+rV3Y5KqbCiiV6FrlOnYPhwmDQJ7rsPPvwQypd3Oyqlwo4uU6xC06FD9pJ/ixfD88/bGr0On1SqQDTRq9Dzyy92IlRysp0MNXy42xEpFdY00avQkpQE11wDx4/D3LnQs6fbESkV9rSNXoWOBQuga1fbRLNkiSZ5pYJEE70KDR98YJtr6teH5cuhdWu3I1IqYmiiV+4yBp57DkaMsFeFWrIE6tbN+zilVMA00Sv3nD1r15B/+GEYNgy+/hqqVnU7KqUijiZ65Y6TJ+GGG+zSwg8+CO+/D+XKuR2VUhFJR92o4nfggL0S1LJldjLU/fe7HZFSEU0TvSpeO3bYTtedO+0iZUOGuB2RUhFPE70qPmvW2DHyp0/bNWu6dnU7IqVKBG2jV8Vj7lzo3t22w3/3nSZ5pYqRJnpV9P71L+jXDy67zLbLt2jhdkRKlSia6FXRMQb+9je49Vbo0cMuUHbJJW5HpVSJo230qmhkZMA998DkyXDzzfDOO1C2rNtRKVUiaY1eBd/x4zBwoE3yjzwC06ZpklfKRVqjV8GVlmbb4xMT4fXX4e673Y5IqRJPE70Knp9+gr59ISUFPvkEBgxwOyKlFJroVbCsXGlr8ufOwTffQKdObkeklHJoG70qvC+/tGvHV6oE33+vSV6pEKOJXhXO22/bJpoWLewY+aZN3Y5IKeVHE70qGGPgiSdg7Fjo0wcWLYKLLnI7KqVUNrSNXuXfmTNw550wdaqdDPXWW1CmjNtRKaVyoDV6lT/HjtklhqdOtTX6d9/VJK9UiNMavQrcr7/CtddCUpJtmx8zxu2IlFIB0ESvArNli11Hfu9e+Pxzm/CVUmFBE73K27JlcN11UKqU7XRt187tiJRS+RBQG72I9BWRLSKyTUQezqa8vogsEJF1IrJIROr6lUeLSIqIvBqswFUx+ewz6NULqlWzCV+TvFJhJ89ELyJRwGvA1UAMMFxEYvx2ex6YboyJBSYAz/qVPwUsLny4qli9/joMHgyxsXYi1GWXuR2RUqoAAqnRtwe2GWO2G2NOAzMB/0VMYoBvnPsLvctFpC1wEfC/woerioUxdtXJe+6xl/775huoVcvtqJRSBRRIoq8D7PJ6nOJs85YEDHLuDwQqi0gNESkFvAA8mNsLiMhYEUkUkcS0tLTAIldF4/RpGDUK/v53O1b+00/hggvcjkopVQjBGkf/INBdRH4AugO7gbPA74GvjDEpuR1sjJlsjEkwxiTU0pqje44csaNp3nvPXhnqjTegtPbXKxXuAvlfvBu41OtxXWdbJmPMHpwavYhUAgYbYw6LSCegq4j8HqgElBWRY8aY8zp0lcv27LHNNBs32slQo0e7HZFSKkgCSfSrgCYi0hCb4IcBN3nvICI1gYPGmHPAI8AUAGPMCK99RgMJmuRD0KZNdoz8wYN2JcqrrnI7IqVUEOXZdGOMyQDGAXOBzcAsY8xGEZkgIv2d3XoAW0RkK7bj9ekiilcF25Il0LmzbZv/9ltN8kpFIDHGuB2Dj4SEBJOYmOh2GCXDRx/ByJHQoAF8/bX9VykVlkRktTEmIbsyXdSspJo0CW68Edq2he++0ySvVATTRF/SnDsHDz4I48fD9dfD/PlQo4bbUSmlipCOnStJfvvNjqaZORPGjbO1+qgot6NSShUxTfQlxeHDtgb/7bfw3HPw0EMg4nZUSqlioIm+JNi1yw6f3LoV3n8fbrop72OUUhFDE32kW7/eJvmjR2HOHLjiCrcjUkoVM+2MjWQLF0KXLnaRsiVLNMkrVUJpoo9UM2bYyU9169p15GNj3Y5IKeUSTfSRxhiYONG2w3fqBEuXQr16bkellHKRJvpIcvYs3H8//OlPdjLU3Ln2ylBKqRJNE32kOHkShg6FV16xk6FmzIDy5d2OSikVAnTUTSQ4eBD697eX+3vxRZvolVLKoYk+3O3caYdPbt9uZ7zeeKPbESmlQowm+nC2dq1N8qdOwf/+B927ux2RUioEaRt9uJo3D7p2hTJl7MgaTfJKqRxoog9H06fby/41amTHyLds6XZESqkQpok+nBgDzzwDt9wC3brB4sVQp47bUSmlQpy20YeLs2ft0sJvvmknQ02dCmXLuh2VUioMaI0+HJw4AYMG2ST/5z/Dv/+tSV4pFTCt0Ye6/fvhuutgxQp49VW45x63I1JKhRlN9KHsp5/s8Mldu+Djj2HgQLcjUkqFIU30oSoxEa69FjIy7HVdO3d2OyKlVJjSNvpQNGcO9OgBFSvCd99pkldKFYom+lDz7ru2Tb5pUztGvnlztyNSSoU5TfShwhh48kkYM8ZeCerbb6F2bbejUkpFAG2jDwUZGXDXXbY2f8st8PbbdmkDpZQKAq3Ru+3YMRgwwCb5xx6zE6E0ySulgkhr9G7auxf69YM1a+xkqDvvdDsipVQE0kTvlq1b7Rj51FT47DPbAauUUkVAE70bli+3NXkRWLgQOnRwOyKlVATTNvri9sUX0KsXVK1qL/2nSV4pVcQ00RenN9+0yxi0amWTfJMmbkeklCoBAkr0ItJXRLaIyDYReTib8voiskBE1onIIhGp62xvIyLLRGSjUzY02G8gLBgDjz4Kd98Nffva5poLL3Q7KqVUCZFnoheRKOA14GogBhguIjF+uz0PTDfGxAITgGed7SeAUcaYlkBfYJKIVA1W8GHh9GkYPdpeMGTMGPj8c7jgArejUkqVIIHU6NsD24wx240xp4GZwAC/fWKAb5z7Cz3lxpitxphk5/4eYB9QKxiBh4WjR22n6/Tp8Ne/wuTJUFr7v5VSxSuQRF8H2OX1OMXZ5i0JGOTcHwhUFpEa3juISHugLPCT/wuIyFgRSRSRxLS0tEBjD22pqfZyf998A1OmwOOP21E2SilVzILVGfsg0F1EfgC6A7uBs55CEbkY+DdwqzHmnP/BxpjJxpgEY0xCrVoRUOHfvBk6dYLkZJg9G2691e2IlFIlWCDtCLuBS70e13W2ZXKaZQYBiEglYLAx5rDzOBr4L5q+W8cAABUdSURBVPCoMWZ5MIIOaUuXQv/+dhmDRYsgIcHtiJRSJVwgNfpVQBMRaSgiZYFhwBfeO4hITRHxPNcjwBRne1ngU2xH7UfBCztEffIJXHkl1KxplxjWJK+UCgF5JnpjTAYwDpgLbAZmGWM2isgEEenv7NYD2CIiW4GLgKed7TcC3YDRIrLWubUJ9psICa+8AkOGQHy8HSPfqJHbESmlFABijHE7Bh8JCQkmMTHR7TACd+4cPPwwTJxoV6H84AN7ZSilguDMmTOkpKRw6tQpt0NRIaJ8+fLUrVuXMn6r3IrIamNMts0IOtavMH77zXa0zphhJ0O98gpERbkdlYogKSkpVK5cmQYNGiA6aqvEM8Zw4MABUlJSaNiwYcDH6RIIBZWeblefnDEDnn0WXntNk7wKulOnTlGjRg1N8goAEaFGjRr5/oWnNfqCSEmBa66xwyinT4ebb3Y7IhXBNMkrbwX5PGiiz68NG2xNPj0dvvoKevd2OyKllMqVNt3kx6JF0KULnD0LixdrklcR78CBA7Rp04Y2bdpQu3Zt6tSpk/n49OnTAT3HrbfeypYtW3Ld57XXXuP9998PRsgqG1qjD9SHH8KoUXDZZTBnDtSv73ZEShW5GjVqsHbtWgCefPJJKlWqxIMPPuizjzEGYwylSmVfb5w6dWqer3PPPfcUPthilpGRQekwWbtKa/SBePFFGDbMXiRk6VJN8sodf/gD9OgR3Nsf/lCgULZt20ZMTAwjRoygZcuWpKamMnbsWBISEmjZsiUTJkzI3LdLly6sXbuWjIwMqlatysMPP0xcXBydOnVi3759ADz22GNMmjQpc/+HH36Y9u3b06xZM77//nsAjh8/zuDBg4mJiWHIkCEkJCRkfgl5e+KJJ2jXrh2tWrXirrvuwjOEfOvWrfTq1Yu4uDji4+PZuXMnAM888wytW7cmLi6ORx991CdmgF9//ZXGjRsD8M4773D99dfTs2dPrrrqKo4cOUKvXr2Ij48nNjaWL7/8MjOOqVOnEhsbS1xcHLfeeivp6ek0atSIjIwMAA4dOuTzuChpos/NuXMwfjw88ICdDPW//0H16m5HpVRI+PHHHxk/fjybNm2iTp06/P3vfycxMZGkpCTmzZvHpk2bzjsmPT2d7t27k5SURKdOnZgyZUq2z22MYeXKlUycODHzS+OVV16hdu3abNq0if/7v//jhx9+yPbY+++/n1WrVrF+/XrS09P5+uuvARg+fDjjx48nKSmJ77//ngsvvJDZs2czZ84cVq5cSVJSEg888ECe7/uHH37gk08+YcGCBVSoUIHPPvuMNWvWMH/+fMaPHw9AUlISzz33HIsWLSIpKYkXXniBKlWq0Llz58x4ZsyYwQ033FAsvwrC43eHG06dsqNpPvoI7rvP1up1+KRyk1PjDRWXXXYZCV7LfMyYMYN3332XjIwM9uzZw6ZNm4iJ8b10RYUKFbj66qsBaNu2LUuWLMn2uQcNGpS5j6fmvXTpUv785z8DEBcXR8uWLbM9dsGCBUycOJFTp06xf/9+2rZtS8eOHdm/fz/XXXcdYCcdAcyfP5/bbruNChUqAFA9gIpcnz59qFatGmC/kB5++GGWLl1KqVKl2LVrF/v37+ebb75h6NChmc/n+XfMmDG8/PLL9OvXj6lTp/Lvf/87z9cLBk302Tl0yM5yXbIEnn8e/vhHXWJYKT8XeF1AJzk5mZdeeomVK1dStWpVRo4cme1Y77Jly2bej4qKyrHZoly5cnnuk50TJ04wbtw41qxZQ506dXjssccKNKu4dOnSnDtnF9r1P977fU+fPp309HTWrFlD6dKlqVu3bq6v1717d8aNG8fChQspU6YMzZs3z3dsBaFNN/5++QU6d4YVK+xkqAce0CSvVB6OHDlC5cqViY6OJjU1lblz5wb9NTp37sysWbMAWL9+fbZNQydPnqRUqVLUrFmTo0eP8vHHHwNQrVo1atWqxezZswGbvE+cOEHv3r2ZMmUKJ0+eBODgwYMANGjQgNWrVwPw0Uc5r8eYnp7OhRdeSOnSpZk3bx67d9uFfXv16sWHH36Y+XyefwFGjhzJiBEjuLUYly/XRO8tKQk6doQ9e2DuXNsBq5TKU3x8PDExMTRv3pxRo0bRuXPnoL/Gvffey+7du4mJieGvf/0rMTExVKlSxWefGjVqcMsttxATE8PVV19Nhw4dMsvef/99XnjhBWJjY+nSpQtpaWn069ePvn37kpCQQJs2bfjnP/8JwEMPPcRLL71EfHw8hw4dyjGmm2++me+//57WrVszc+ZMmjRpAtimpT/96U9069aNNm3a8NBDD2UeM2LECNLT0xk6tPguoa2LmnnMnw+DBkF0tB0+2bp18ceglJ/NmzfTokULt8MICRkZGWRkZFC+fHmSk5Pp06cPycnJYTPE0WPmzJnMnTs3oGGnOcnuc6GLmuXlvffs4mTNm9skX7eu2xEppfwcO3aMK664goyMDIwxvPXWW2GX5O+++27mz5+fOfKmuITXWQo2Y+C55+CRR+yY4k8/hapV3Y5KKZWNqlWrZrabh6s33njDldctuW30Z8/CuHE2yQ8bBl9/rUleKRWRSmaiP3nSToB6/XV48EF4/31whnMppVSkKXlNN/v324t3L18OL71kJ0MppVQEK1mJfscO6NsXfv4Z/vMfGDzY7YiUUqrIlZymm9WroVMnSEuzQyk1ySuVp549e543+WnSpEncfffduR5XqVIlAPbs2cOQIUOy3adHjx7kNZR60qRJnDhxIvPxNddcw+HDhwMJXXkpGYn+66+he3fbDv/dd3ZNeaVUnoYPH87MmTN9ts2cOZPhw4cHdPwll1yS68zSvPgn+q+++oqqYTRowhiTuZSCmyI/0U+dCv36QePGsGwZ6OQTFabcWKV4yJAh/Pe//828yMjOnTvZs2cPXbt2zRzXHh8fT+vWrfn888/PO37nzp20atUKsMsTDBs2jBYtWjBw4MDMZQfAji/3LHH8xBNPAPDyyy+zZ88eevbsSc+ePQG7NMH+/fsBePHFF2nVqhWtWrXKXOJ4586dtGjRgjvuuIOWLVvSp08fn9fxmD17Nh06dODyyy/nyiuvZO/evYAdq3/rrbfSunVrYmNjM5dQ+Prrr4mPjycuLo4rrrgCsOvzP//885nP2apVK3bu3MnOnTtp1qwZo0aNolWrVuzatSvb9wewatUqfve73xEXF0f79u05evQo3bp181l+uUuXLiQlJeX+h8pD5LbRGwN/+xs8/ri9EtRHH9lZr0qpgFWvXp327dszZ84cBgwYwMyZM7nxxhsREcqXL8+nn35KdHQ0+/fvp2PHjvTv3z/Ha5q+8cYbVKxYkc2bN7Nu3Tri4+Mzy55++mmqV6/O2bNnueKKK1i3bh333XcfL774IgsXLqRmzZo+z7V69WqmTp3KihUrMMbQoUMHunfvTrVq1UhOTmbGjBm8/fbb3HjjjXz88ceMHDnS5/guXbqwfPlyRIR33nmHf/zjH7zwwgs89dRTVKlShfXr1wN2zfi0tDTuuOMOFi9eTMOGDX3WrclJcnIy06ZNo2PHjjm+v+bNmzN06FA+/PBD2rVrx5EjR6hQoQK33347//rXv5g0aRJbt27l1KlTxMXF5evv5i8yE31GBvz+9/D223ap4XfeAa9V85QKR26tUuxpvvEk+nfffRewzRJ/+ctfWLx4MaVKlWL37t3s3buX2rVrZ/s8ixcv5j5nlFtsbCyxsbGZZbNmzWLy5MlkZGSQmprKpk2bfMr9LV26lIEDB2auJDlo0CCWLFlC//79adiwIW3atAF8lzn2lpKSwtChQ0lNTeX06dM0bNgQsMsWezdVVatWjdmzZ9OtW7fMfQJZyrh+/fqZST6n9yciXHzxxbRr1w6AaKciesMNN/DUU08xceJEpkyZwujRo/N8vbxEXtPN8eNw/fU2yT/yCEybpkleqUIYMGAACxYsYM2aNZw4cYK2bdsCdpGwtLQ0Vq9ezdq1a7nooosKtCTwjh07eP7551mwYAHr1q3j2muvLdDzeJTzmhOT0zLH9957L+PGjWP9+vW89dZbhV7KGHyXM/Zeyji/769ixYr07t2bzz//nFmzZjFixIh8x+YvshL9vn3Qs6ddr+b11+GZZ3SJYaUKqVKlSvTs2ZPbbrvNpxPWs0RvmTJlWLhwIT///HOuz9OtWzc++OADADZs2MC6desAu8TxBRdcQJUqVdi7dy9z5szJPKZy5cocPXr0vOfq2rUrn332GSdOnOD48eN8+umndO3aNeD3lJ6eTp06dQCYNm1a5vbevXvz2muvZT4+dOgQHTt2ZPHixezYsQPwXcp4zZo1AKxZsyaz3F9O769Zs2akpqayatUqAI4ePZr5pTRmzBjuu+8+2rVrl3mRk8KInET/yy/wu9/Bhg3wySeQx/AvpVTghg8fTlJSkk+iHzFiBImJibRu3Zrp06fneRGNu+++m2PHjtGiRQsef/zxzF8GcXFxXH755TRv3pybbrrJZ4njsWPH0rdv38zOWI/4+HhGjx5N+/bt6dChA2PGjOHyyy8P+P08+eST3HDDDbRt29an/f+xxx7j0KFDtGrViri4OBYuXEitWrWYPHkygwYNIi4uLnN54cGDB3Pw4EFatmzJq6++StOmTbN9rZzeX9myZfnwww+59957iYuLo3fv3pk1/bZt2xIdHR20NesjZ5niEyfgxhvh0UfteHmlIoAuU1wy7dmzhx49evDjjz9SqtT59fH8LlMcOTX6ihXhyy81ySulwtr06dPp0KEDTz/9dLZJviAic9SNUkqFqVGjRjFq1KigPmfk1OiVilCh1ryq3FWQz4MmeqVCWPny5Tlw4IAmewXYJH/gwAHKly+fr+O06UapEFa3bl1SUlJIS0tzOxQVIsqXL0/dfF7uNKBELyJ9gZeAKOAdY8zf/crrA1OAWsBBYKQxJsUpuwV4zNn1b8aYaSilAlKmTJnMGZlKFVSeTTciEgW8BlwNxADDRSTGb7fngenGmFhgAvCsc2x14AmgA9AeeEJECj/6XymlVMACaaNvD2wzxmw3xpwGZgID/PaJAb5x7i/0Kr8KmGeMOWiMOQTMA/oWPmyllFKBCiTR1wF2eT1OcbZ5SwIGOfcHApVFpEaAxyIiY0UkUUQStS1SKaWCK1idsQ8Cr4rIaGAxsBs4G+jBxpjJwGQAEUkTkdwXzchdTWB/IY4vKhpX/mhc+aNx5U8kxlU/p4JAEv1u4FKvx3WdbZmMMXtwavQiUgkYbIw5LCK7gR5+xy7K7cWMMbUCiClHIpKY0zRgN2lc+aNx5Y/GlT8lLa5Amm5WAU1EpKGIlAWGAV/4BVdTRDzP9Qh2BA7AXKCPiFRzOmH7ONuUUkoVkzwTvTEmAxiHTdCbgVnGmI0iMkFE+ju79QC2iMhW4CLgaefYg8BT2C+LVcAEZ5tSSqliElAbvTHmK+Arv22Pe93/CMj2CsDGmClk1fCLw+RifK380LjyR+PKH40rf0pUXCG3TLFSSqng0rVulFIqwmmiV0qpCBc2iV5E+orIFhHZJiIPZ1NeTkQ+dMpXiEgDr7JHnO1bROSqYo7rjyKySUTWicgCZ10gT9lZEVnr3L7wP7aI4xrtzFnwvP4Yr7JbRCTZud1SzHH90yumrSJy2KusKM/XFBHZJyIbcigXEXnZiXudiMR7lRXl+corrhFOPOtF5HsRifMq2+lsXysiBbhsW6Hi6iEi6V5/r8e9ynL9DBRxXA95xbTB+UxVd8qK8nxdKiILnVywUUTuz2afovuMGWNC/oZdTO0noBFQFjsTN8Zvn98Dbzr3hwEfOvdjnP3LAQ2d54kqxrh6AhWd+3d74nIeH3PxfI0GXs3m2OrAduffas79asUVl9/+9wJTivp8Oc/dDYgHNuRQfg0wBxCgI7CiqM9XgHH9zvN62PWoVniV7QRqunS+egBfFvYzEOy4/Pa9DvimmM7XxUC8c78ysDWb/5NF9hkLlxp9IOvtDAA8K2N+BFwhIuJsn2mM+c0YswPY5jxfscRljFlojDnhPFyOnTRW1AI5XzkpyvWJ8hvXcGBGkF47V8aYxdiVV3MyALtwnzHGLAeqisjFFPF6TnnFZYz53nldKL7PVyDnKyeF+WwGO67i/HylGmPWOPePYoeq+y8HU2SfsXBJ9IGsmZO5j7Fj/9OBgNfbKcK4vN2O/cb2KC92jZ/lInJ9kGLKT1yDnZ+IH4mIZ/ZzSJwvp4mrIVmL5UHRna9A5BR7UZ6v/PL/fBngfyKyWkTGuhBPJxFJEpE5ItLS2RYS50tEKmKT5cdem4vlfIltVr4cWOFXVGSfMb3wSDERkZFAAtDda3N9Y8xuEWkEfCMi640xPxVTSLOBGcaY30TkTuyvoV7F9NqBGAZ8ZIzxXjPJzfMV0kSkJzbRd/Ha3MU5XxcC80TkR6fGWxzWYP9ex0TkGuAzoEkxvXYgrgO+M74TOIv8fIldIuZj4A/GmCPBfO7chEuNPs/1drz3EZHSQBXgQIDHFmVciMiVwKNAf2PMb57txpjdzr/bsWsAXV5ccRljDnjF8g7QNtBjizIuL8Pw+1ldhOcrEDnFXpTnKyAiEov9Gw4wxhzwbPc6X/uATwlek2WejDFHjDHHnPtfAWVEpCYhcL4cuX2+iuR8iUgZbJJ/3xjzSTa7FN1nrCg6HoJ9w/7y2I79Ke/pwGnpt889+HbGznLut8S3M3Y7weuMDSSuy7GdT038tlcDyjn3awLJBKlTKsC4Lva6PxBYbrI6fnY48VVz7lcvrric/ZpjO8akOM6X12s0IOfOxWvx7ShbWdTnK8C46mH7nX7nt/0CoLLX/e+BvsUYV23P3w+bMH9xzl1An4Giisspr4Jtx7+guM6X896nA5Ny2afIPmNBO7lFfcP2SG/FJs1HnW0TsLVkgPLAf5wP/UqgkdexjzrHbQGuLua45gN7gbXO7Qtn+++A9c4HfT1wezHH9Syw0Xn9hUBzr2Nvc87jNuDW4ozLefwk8He/44r6fM0AUoEz2DbQ24G7gLuccsFeae0n5/UTiul85RXXO8Ahr89XorO9kXOukpy/86PFHNc4r8/Xcry+iLL7DBRXXM4+o7EDNLyPK+rz1QXbB7DO6291TXF9xnQJBKWUinDh0kavlFKqgDTRK6VUhNNEr5RSEU4TvVJKRThN9EopFeE00SulVITTRK+UUhHu/wFCtaowxxa7AAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now click the 'Submit Assignment' button above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When you're done or would like to take a break, please run the two cells below to save your work and close the Notebook. This will free up resources for your fellow learners. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "<!-- Save the notebook -->\n",
       "IPython.notebook.save_checkpoint();\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "<!-- Save the notebook -->\n",
    "IPython.notebook.save_checkpoint();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.session.delete();\n",
       "window.onbeforeunload = null\n",
       "setTimeout(function() { window.close(); }, 1000);\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.session.delete();\n",
    "window.onbeforeunload = null\n",
    "setTimeout(function() { window.close(); }, 1000);"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 7 - Question.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "convolutional-neural-networks-tensorflow",
   "graded_item_id": "csg1x",
   "launcher_item_id": "GpKYz"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
